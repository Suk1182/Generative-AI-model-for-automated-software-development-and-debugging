{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN9_-geguTDv"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Prepare the dataset\n",
        "def load_dataset(file_path, tokenizer, block_size=128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=file_path,\n",
        "        block_size=block_size,\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# Load your dataset (e.g., code_snippets.txt)\n",
        "train_dataset = load_dataset(\"data/code_snippets.txt\", tokenizer)\n",
        "\n",
        "# Set up data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False,\n",
        ")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-codegen\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"./gpt2-codegen\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-codegen\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "@app.route('/generate_code', methods=['POST'])\n",
        "def generate_code():\n",
        "    input_text = request.json.get('inputText', '')\n",
        "    inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    outputs = model.generate(inputs, max_length=150)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return jsonify({'generatedCode': generated_text})\n",
        "\n",
        "@app.route('/debug_code', methods=['POST'])\n",
        "def debug_code():\n",
        "    # Placeholder for debugging functionality\n",
        "    return jsonify({'debugResult': \"Debugging not implemented yet.\"})\n",
        "\n",
        "@app.route('/refactor_code', methods=['POST'])\n",
        "def refactor_code():\n",
        "    # Placeholder for refactoring functionality\n",
        "    return jsonify({'refactorResult': \"Refactoring not implemented yet.\"})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000, debug=True)\n"
      ],
      "metadata": {
        "id": "lWReermiuXdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import React, { useState } from 'react';\n",
        "import axios from 'axios';\n",
        "\n",
        "function CodeGenerator() {\n",
        "    const [inputText, setInputText] = useState('');\n",
        "    const [generatedCode, setGeneratedCode] = useState('');\n",
        "\n",
        "    const handleGenerate = async () => {\n",
        "        try {\n",
        "            const response = await axios.post('/generate_code', { inputText });\n",
        "            setGeneratedCode(response.data.generatedCode);\n",
        "        } catch (error) {\n",
        "            console.error('Error generating code:', error);\n",
        "        }\n",
        "    };\n",
        "\n",
        "    return (\n",
        "        <div>\n",
        "            <textarea\n",
        "                value={inputText}\n",
        "                onChange={(e) => setInputText(e.target.value)}\n",
        "                placeholder=\"Describe the functionality...\"\n",
        "            />\n",
        "            <button onClick={handleGenerate}>Generate Code</button>\n",
        "            <pre>{generatedCode}</pre>\n",
        "        </div>\n",
        "    );\n",
        "}\n",
        "\n",
        "export default CodeGenerator;\n"
      ],
      "metadata": {
        "id": "1KO2IzEwuZua"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}